# 围棋与博弈论的关系（结合本项目前端展示）

本文用博弈论视角解释围棋对弈，并说明本项目如何在前端展示和利用这些概念。

---

## 1. 围棋的博弈论属性
- **完全信息、零和博弈**：棋盘状态对双方透明，胜负是零和（你的收益即我的损失）。
- **策略空间巨大**：19×19，每一步最多 361+pass，搜索树爆炸，需借助概率先验和搜索裁剪。
- **纳什均衡视角**：理想博弈解是双方最优策略构成的均衡；实际用 MCTS + 神经网络近似“强策略”。
- **探索 vs 利用**：MCTS 的 UCB/PUCT 在“尝试新招”(探索)和“复用好招”(利用)间平衡，契合多臂赌博机的博弈思想。

---

## 2. 本项目的博弈建模
- **策略先验（PolicyNet）**：为每个合法动作给出概率，近似“当前局面的理性策略分布”，指导搜索分支排序。
- **价值评估（ValueNet）**：给出局面胜率，近似“状态效用”，降低深层长链模拟的成本。
- **搜索（MCTS）**：用先验 + 模拟 + 价值回溯逼近最优响应，得到更接近均衡的落子选择。
- **快速模拟（PlayoutNet）**：作为“廉价弱策略”加速 roll-out，提供粗粒度趋势估计。

---

## 3. 与围棋规则/特征的结合
- **合法性与气/劫**：规则引擎确保落子合法，特征显式编码气数、打劫、历史步，使网络理解“紧迫与禁着”。
- **局面价值与形势**：价值网络输出胜率；结合搜索访问次数可反映优势/劣势、官子收束质量。
- **平衡与均衡**：MCTS 的访问分布可视作对当前局面的一种“混合策略近似”，在复杂局面中保持稳健。

---

## 4. 前端如何呈现博弈信息（front-ksy）
- **胜率曲线 / 形势判断**：基于 ValueNet + 搜索结果，展示随手数变化的胜率曲线，体现局面效用变化。
- **落子热力图**：使用 PolicyNet/MCTS 访问分布绘制热力/推荐点，呈现“理性策略概率”。
- **建议列表 / 主推手**：依据搜索访问次数与价值排序，给出前若干最优候选。
- **对局分析面板**：展示当前胜率、推荐落子、分支比较，帮助理解当前局面的“策略均衡趋势”。
- **代理配置**：前端通过 Vite 代理 `/api` 到后端，实时获取 MCTS + NN 结果并渲染。

---

## 5. 训练数据与博弈含义
- **策略数据（policyData.pt）**：来自棋谱的真实落子分布，近似高水平人类/引擎的“混合策略”。
- **价值数据（valueData.pt）**：终局胜负标签，对应局面效用的监督信号。
- **损失与优化**：交叉熵逼近理性策略分布，MSE 逼近真实胜率；StepLR 调度在训练后期稳定收敛。

---

## 6. 端到端闭环（博弈论视角）
1) 前端提交局面 → 后端生成策略先验与搜索结果。  
2) MCTS 以先验和价值评估平衡探索/利用，输出推荐落子（混合策略近似）。  
3) 前端可视化胜率、热力、建议，帮助人类理解“当前局面的合理应对”。  
4) 持续交互，迭代生成更接近均衡的对弈过程。

---

## 7. 关键代码索引
- 规则与特征：`go.py`、`features.py`
- 网络：`net.py`（PolicyNet / PlayoutNet / ValueNet）
- 搜索与落子：`genMove.py`（含 MCTS）、`gtp.py`
- 训练：`train.py`、`train_all.py`
- 前端展示：`front-ksy/`（Vue 3 + ECharts 热力/曲线 + Sabaki 棋盘组件）





